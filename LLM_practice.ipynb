{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt \n",
    "import time\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASTER_CONFIG = {\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tinyshakespare.txt', <http.client.HTTPMessage at 0x16eb33a51e0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "file_name = \"tinyshakespare.txt\"\n",
    "urllib.request.urlretrieve(url,file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing the first 10 characters of the vocab list: ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3']\n",
      "Total number of character in our dataset (Vocabulary Size): 65\n"
     ]
    }
   ],
   "source": [
    "#dataset 읽기\n",
    "lines = open(\"tinyshakespare.txt\", 'r').read()\n",
    "vocab = sorted(list(set(lines)))\n",
    "print('Printing the first 10 characters of the vocab list:', vocab[:10])\n",
    "print('Total number of character in our dataset (Vocabulary Size):', len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping하기\n",
    "#integers to characters(itos) and characters to integers(stoi)\n",
    "itos = {i: ch for i, ch in enumerate(vocab)}\n",
    "stoi = {ch: i for i, ch in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'morning'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encoding function\n",
    "def encode(s):\n",
    "    return [stoi[ch] for ch in s]\n",
    "#Decode\n",
    "def decode(l):\n",
    "    return''.join([itos[i] for i in l])\n",
    "\n",
    "#example\n",
    "decode(encode(\"morning\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394])\n"
     ]
    }
   ],
   "source": [
    "#pytorch 이용하기\n",
    "dataset = torch.tensor(encode(lines), dtype=torch.int8)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(data, split, batch_size, context_window, config=MASTER_CONFIG):\n",
    "    #training, validation, test sets 나누기\n",
    "    train = data[:int(.8 * len(data))]\n",
    "    val = data[int(.8 * len(data)): int(.9 * len(data))]\n",
    "    test = data[int(.9 *len(data)):]\n",
    "\n",
    "    batch_data = train\n",
    "    if split == 'val':\n",
    "        batch_data = val\n",
    "    if split == 'test':\n",
    "        batch_data = test\n",
    "\n",
    "    ix = torch.randint(0, batch_data.size(0) - context_window - 1, (batch_size,))\n",
    "\n",
    "    x = torch.stack([batch_data[i:i+context_window] for i in ix]).long()\n",
    "    y = torch.stack([batch_data[i+1:i+context_window+1] for i in ix]).long()\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASTER_CONFIG.update({\n",
    "    'batch_size':8,\n",
    "    'context_window': 16\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(' yea, the\\ntwo tr', 'yea, the\\ntwo tri'), ('d have none\\nshor', ' have none\\nshort'), ('the duke asleep:', 'he duke asleep:\\n'), ('t they are\\npast ', ' they are\\npast c'), (' your sons,\\nTo m', 'your sons,\\nTo ma'), (' cousin; farewel', 'cousin; farewell'), ('it. Fewness and ', 't. Fewness and t'), ('le and false.\\n\\nH', 'e and false.\\n\\nHE')]\n"
     ]
    }
   ],
   "source": [
    "xs, ys = get_batches(dataset, 'train', MASTER_CONFIG['batch_size'], MASTER_CONFIG['context_window'])\n",
    "decoded_samples = [(decode(xs[i].tolist()), decode(ys[i].tolist())) for i in range(len(xs))]\n",
    "print(decoded_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_loss(model,config=MASTER_CONFIG):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        losses = []\n",
    "\n",
    "        for _ in range(10):\n",
    "            xb, yb = get_batches(dataset, split, config['batch_size'], config['context_window'])\n",
    "            _, loss = model(xb, yb)\n",
    "            losses.append(loss.item())\n",
    "        out[split] = np.mean(losses)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
